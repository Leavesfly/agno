# 智能体知识库

<cite>
**本文档中引用的文件**  
- [knowledge.py](file://libs/agno/agno/knowledge/knowledge.py)
- [fixed.py](file://libs/agno/agno/knowledge/chunking/fixed.py)
- [recursive.py](file://libs/agno/agno/knowledge/chunking/recursive.py)
- [semantic.py](file://libs/agno/agno/knowledge/chunking/semantic.py)
- [openai.py](file://libs/agno/agno/knowledge/embedder/openai.py)
- [pdf_reader.py](file://libs/agno/agno/knowledge/reader/pdf_reader.py)
- [web_search_reader.py](file://libs/agno/agno/knowledge/reader/web_search_reader.py)
- [text_reader.py](file://libs/agno/agno/knowledge/reader/text_reader.py)
- [pgvector.py](file://libs/agno/agno/vectordb/pgvector/pgvector.py)
- [strategy.py](file://libs/agno/agno/knowledge/chunking/strategy.py)
- [base.py](file://libs/agno/agno/knowledge/reader/base.py)
</cite>

## 目录
1. [引言](#引言)
2. [知识库核心概念](#知识库核心概念)
3. [工作流程详解](#工作流程详解)
4. [数据加载与读取器](#数据加载与读取器)
5. [分块策略](#分块策略)
6. [嵌入模型](#嵌入模型)
7. [向量数据库](#向量数据库)
8. [端到端代码示例](#端到端代码示例)
9. [结论](#结论)

## 引言
智能体知识库是现代人工智能系统的核心组件，它为智能体提供了一个集中存储和检索静态、结构化信息的机制。这些信息可以包括文档、网页内容、数据库记录等，是智能体进行推理、决策和回答用户问题的重要依据。本文档将深入探讨智能体知识库的完整工作流程，从数据加载、分块处理、向量化到向量数据库存储和检索，旨在为开发者提供一个全面的技术指南。

## 知识库核心概念
知识库（Knowledge）是用于存储和检索可供所有智能体访问的静态、结构化信息的系统。其核心目标是将非结构化的文本信息转换为智能体可以高效理解和查询的结构化向量表示。知识库中的信息是持久化的，可以被多个智能体共享和复用，从而避免了每次查询都需要重新获取和处理原始数据的开销。通过知识库，智能体能够结合外部知识源和用户记忆，提供更加准确和上下文相关的回答。

**Section sources**
- [knowledge.py](file://libs/agno/agno/knowledge/knowledge.py)

## 工作流程详解
智能体知识库的完整工作流程可以分为四个主要阶段：数据加载、内容分块、向量化和向量存储与检索。

1.  **数据加载**：这是流程的起点，知识库从多种来源加载原始数据。这些来源包括本地文件路径、远程URL、云存储（如S3、GCS）以及数据库等。加载过程由专门的读取器（Reader）负责，它们能够解析不同格式的文件（如PDF、CSV、TXT等）并提取出纯文本内容。
2.  **内容分块**：由于大型语言模型（LLM）有输入长度的限制，直接将长文档输入模型是不可行的。因此，需要将提取出的文本内容切分为更小的片段，这个过程称为“分块”（Chunking）。分块策略的选择至关重要，它直接影响后续检索的准确性和效率。
3.  **向量化**：分块后的文本片段需要被转换为机器可以理解的数学表示，即向量。这一步由嵌入模型（Embedder）完成。嵌入模型会将每个文本片段映射到一个高维向量空间中的点，语义上相似的文本在向量空间中的距离会更近。
4.  **向量存储与检索**：生成的向量及其对应的元数据（如原始文本、来源信息等）被存储到专门的向量数据库（Vector DB）中。当用户提出问题时，问题本身也会被相同的嵌入模型转换为向量，然后在向量数据库中进行相似性搜索，找出与问题向量最接近的几个文本片段，这些片段将作为上下文提供给智能体，用于生成最终的回答。

```mermaid
flowchart TD
A[数据源] --> B[读取器]
B --> C[原始文本]
C --> D[分块策略]
D --> E[文本片段]
E --> F[嵌入模型]
F --> G[向量表示]
G --> H[向量数据库]
H --> I[用户查询]
I --> F
I --> J[相似性搜索]
J --> K[相关文本片段]
K --> L[智能体]
L --> M[生成回答]
```

**Diagram sources**
- [knowledge.py](file://libs/agno/agno/knowledge/knowledge.py)
- [fixed.py](file://libs/agno/agno/knowledge/chunking/fixed.py)
- [openai.py](file://libs/agno/agno/knowledge/embedder/openai.py)
- [pgvector.py](file://libs/agno/agno/vectordb/pgvector/pgvector.py)

## 数据加载与读取器
数据加载是构建知识库的第一步，它决定了知识库可以利用的信息范围。系统通过一系列专门的读取器（Reader）来支持多种数据源。

-   **文件路径读取器**：`add_content` 方法支持从本地文件系统加载文件。它可以处理单个文件或整个目录。对于目录，它会递归地遍历所有文件，并根据文件扩展名自动选择合适的读取器。
-   **URL读取器**：通过 `add_content` 方法的 `url` 参数，可以从网页链接加载内容。系统会验证URL的有效性，然后根据URL的文件扩展名（如 `.pdf`, `.csv`）选择相应的读取器进行处理。
-   **云存储读取器**：系统支持从S3和GCS等云存储服务加载数据。这通过 `RemoteContent` 对象（如 `S3Content` 或 `GCSContent`）来实现，允许指定存储桶、前缀或具体的对象键。
-   **特定格式读取器**：项目提供了针对不同文件格式的专用读取器，例如 `PDFReader` 用于处理PDF文件，`TextReader` 用于处理纯文本文件，`WebSearchReader` 用于通过网络搜索获取内容。

```mermaid
classDiagram
class Reader {
+chunk : bool
+chunk_size : int
+chunking_strategy : ChunkingStrategy
+read(obj : Any, name : str) : Document[]
+async_read(obj : Any, name : str) : Document[]
+chunk_document(document : Document) : Document[]
}
class PDFReader {
+read(pdf : Union~str, Path, IO~) : Document[]
+async_read(pdf : Union~str, Path, IO~) : Document[]
}
class TextReader {
+read(file : Union~Path, IO~) : Document[]
+async_read(file : Union~Path, IO~) : Document[]
}
class WebSearchReader {
+read(query : str) : Document[]
+async_read(query : str) : Document[]
}
Reader <|-- PDFReader
Reader <|-- TextReader
Reader <|-- WebSearchReader
```

**Diagram sources**
- [pdf_reader.py](file://libs/agno/agno/knowledge/reader/pdf_reader.py)
- [text_reader.py](file://libs/agno/agno/knowledge/reader/text_reader.py)
- [web_search_reader.py](file://libs/agno/agno/knowledge/reader/web_search_reader.py)
- [base.py](file://libs/agno/agno/knowledge/reader/base.py)

## 分块策略
分块策略决定了如何将大段文本切分为适合处理的小片段。选择合适的策略对于保持文本的语义完整性至关重要。

-   **固定大小分块**：这是最简单的策略，将文本按固定的字符数（如5000个字符）进行切割，并允许设置重叠（overlap）以避免在句子中间断开。该策略由 `FixedSizeChunking` 类实现。
-   **递归分块**：该策略会尝试在自然的断点（如换行符 `\n` 或句号 `.`）处进行分割，以保持句子和段落的完整性。如果在指定的块大小内找不到断点，则会强制分割。该策略由 `RecursiveChunking` 类实现。
-   **语义分块**：这是一种更高级的策略，它利用嵌入模型来理解文本的语义。它会将文本分割成在语义上连贯的块，而不是简单地按字符或标点分割。这通常能产生质量更高的分块结果。该策略由 `SemanticChunking` 类实现，依赖于 `chonkie` 库。

```mermaid
classDiagram
class ChunkingStrategy {
<<abstract>>
+chunk(document : Document) : Document[]
+clean_text(text : str) : str
}
class FixedSizeChunking {
+chunk_size : int
+overlap : int
+chunk(document : Document) : Document[]
}
class RecursiveChunking {
+chunk_size : int
+overlap : int
+chunk(document : Document) : Document[]
}
class SemanticChunking {
+embedder : Embedder
+chunk_size : int
+similarity_threshold : float
+chunk(document : Document) : Document[]
}
ChunkingStrategy <|-- FixedSizeChunking
ChunkingStrategy <|-- RecursiveChunking
ChunkingStrategy <|-- SemanticChunking
```

**Diagram sources**
- [fixed.py](file://libs/agno/agno/knowledge/chunking/fixed.py)
- [recursive.py](file://libs/agno/agno/knowledge/chunking/recursive.py)
- [semantic.py](file://libs/agno/agno/knowledge/chunking/semantic.py)
- [strategy.py](file://libs/agno/agno/knowledge/chunking/strategy.py)

## 嵌入模型
嵌入模型负责将文本片段转换为向量。系统支持多种嵌入模型提供商。

-   **OpenAI**：`OpenAIEmbedder` 类封装了对 OpenAI 嵌入API的调用，支持 `text-embedding-3-small` 和 `text-embedding-3-large` 等模型。它提供了同步和异步的方法来获取单个或批量文本的嵌入向量。
-   **其他提供商**：项目结构显示，系统还支持 Cohere、HuggingFace、Jina、Mistral 等多家提供商的嵌入模型，通过各自的 `Embedder` 实现类（如 `cohere.py`, `huggingface.py`）进行集成。

```mermaid
classDiagram
class Embedder {
<<abstract>>
+get_embedding(text : str) : float[]
+async_get_embedding(text : str) : float[]
}
class OpenAIEmbedder {
+id : str
+dimensions : int
+get_embedding(text : str) : float[]
+async_get_embedding(text : str) : float[]
+get_embeddings_batch(texts : str[]) : List[]float~~
}
Embedder <|-- OpenAIEmbedder
```

**Diagram sources**
- [openai.py](file://libs/agno/agno/knowledge/embedder/openai.py)

## 向量数据库
向量数据库用于高效地存储和检索向量。系统支持多种流行的向量数据库。

-   **PGVector**：`PgVector` 类实现了与 PostgreSQL 数据库的集成，利用 `pgvector` 扩展来存储和查询向量。它支持多种距离度量（如余弦距离、L2距离）和索引类型（如HNSW、IvfFlat），并提供了向量搜索、关键词搜索和混合搜索等多种搜索模式。
-   **其他支持的数据库**：项目结构中的 `vector_db` 目录表明，系统还支持 Chroma、Qdrant、Pinecone、LanceDB、Weaviate 等多种向量数据库。

```mermaid
classDiagram
class VectorDb {
<<abstract>>
+insert(documents : Document[])
+upsert(documents : Document[])
+search(query : str) : Document[]
}
class PgVector {
+table_name : str
+db_url : str
+embedder : Embedder
+insert(documents : Document[])
+upsert(documents : Document[])
+search(query : str) : Document[]
+vector_search(query : str) : Document[]
+keyword_search(query : str) : Document[]
}
VectorDb <|-- PgVector
```

**Diagram sources**
- [pgvector.py](file://libs/agno/agno/vectordb/pgvector/pgvector.py)

## 端到端代码示例
以下是一个构建智能体知识库的端到端代码示例，展示了如何从外部知识源获取信息并结合用户记忆进行回答。

```python
from agno.knowledge import Knowledge
from agno.vectordb import PgVector
from agno.knowledge.embedder import OpenAIEmbedder
from agno.knowledge.reader import WebSearchReader

# 1. 初始化向量数据库
vector_db = PgVector(
    table_name="my_knowledge_base",
    db_url="postgresql://user:password@localhost:5432/mydb",
    embedder=OpenAIEmbedder(api_key="your-openai-key")
)

# 2. 创建知识库实例
knowledge = Knowledge(
    name="My Knowledge Base",
    vector_db=vector_db,
    max_results=5
)

# 3. 从网络搜索加载知识
web_reader = WebSearchReader(max_results=3)
knowledge.add_content(
    topics=["量子计算最新进展"],
    reader=web_reader
)

# 4. 从本地文件加载知识
knowledge.add_content(path="/path/to/my_document.pdf")

# 5. （在智能体中）使用知识库回答问题
query = "量子计算对金融行业有什么影响？"
relevant_docs = knowledge.search(query)

# 将检索到的文档和用户记忆作为上下文传递给智能体
context = "\n\n".join([doc.content for doc in relevant_docs])
# ... 将 context 和用户记忆一起输入给LLM生成回答 ...
```

**Section sources**
- [knowledge.py](file://libs/agno/agno/knowledge/knowledge.py)
- [pgvector.py](file://libs/agno/agno/vectordb/pgvector/pgvector.py)
- [openai.py](file://libs/agno/agno/knowledge/embedder/openai.py)
- [web_search_reader.py](file://libs/agno/agno/knowledge/reader/web_search_reader.py)

## 结论
智能体知识库是连接原始数据与智能体推理能力的桥梁。通过一个精心设计的工作流程——从多样化的数据源加载，到采用合适的分块策略，再到利用强大的嵌入模型进行向量化，最后存储于高效的向量数据库中——我们可以为智能体构建一个丰富、准确且可快速检索的知识体系。这不仅极大地提升了智能体回答问题的能力，也为构建更复杂、更智能的应用奠定了坚实的基础。开发者应根据具体的应用场景，选择最合适的读取器、分块策略、嵌入模型和向量数据库，以实现最佳的性能和效果。